<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
    
  <title>Resume - Minhao Fan</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet">
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/resume.min.css" rel="stylesheet">

</head>

<body id="page-top">

  <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
      <span class="d-block d-lg-none">Minhao Fan</span>
      <span class="d-none d-lg-block">
        <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="img/profile.jpg" alt="">
      </span>
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav">
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#experience">Experiences</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#education">Education</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#publications">Publications</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#courseprojects">Course Projects</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#awards">Awards</a>
        </li>
        <li class="nav-item">
          <a class="nav-link js-scroll-trigger" href="#skills">Skills</a>
        </li>
      </ul>
    </div>
  </nav>

  <div class="container-fluid p-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="about">
      <div class="w-100">
        <h1 class="mb-0">Minhao
          <span class="text-primary">Fan</span>
        </h1>
        <div class="subheading mb-5">
          <a href="mailto:minhao001@e.ntu.edu.sg">MINHAO001@e.ntu.edu.sg</a>
        </div>
        <p class="lead mb-5">
            Hi, I'm Minhao Fan. I am currently a PhD student at Nanyang Technological University(NTU) supervised by Prof. <a href='https://personal.ntu.edu.sg/liu/'>Weichen Liu</a>. 
			I received my B.S degree in Intelligence Science and Technology from Peking University in 2020. 
			With my previous research focusing on data mining and computer vision related topics, my current research interests lie primarily in <b>Agentic AI</b> and <b>Efficient Multimodal Large Language Model(MLLM)</b>.			
			I focus on minimizing the effort required to solve complex real-world problems with MLLM-based agentic flow, enabling the system to operate more autonomously with minimal prompt engineering expertise required from users.
			Efficient training and inference technologies for LLM such as PEFT, In-context Learning, Flash-Attention and KV Cache are also other aspects of my research.
            I had worked as a research intern at the Spatial and Temporal Restoration Understanding and Compression Team (<a href='http://www.icst.pku.edu.cn/struct/struct.html'>STRUCT</a>)
            at <a href='https://www.icst.pku.edu.cn/'>WICT</a> under the supervision of Prof. <a href='http://39.96.165.147/people/liujiaying.html'>Jiaying Liu</a>.
			I had worked as a research intern at <a href='https://vision-cair.kaust.edu.sa/'>Vision CAIR</a> at KAUST under the supervision of Prof. <a href='https://cemse.kaust.edu.sa/profiles/mohamed-elhoseiny'>Mohamed Elhoseiny</a>.
			I had also worked with the Data to Knowledge Lab at Rice University supervised by Prof. <a href='https://cs.rice.edu/~xh37/index.html'>Xia (Ben) Hu</a>.
        </p>
        <div class="social-icons">
          <a href="https://github.com/XFW-go">
            <i class="fab fa-github"></i>
          </a>
          <a href="#">
            <i class="fab fa-twitter"></i>
          </a>
          <a href="https://www.facebook.com/xfw.xsdxz">
            <i class="fab fa-facebook-f"></i>
          </a>
        </div>
      </div>
    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex justify-content-center" id="experience">
      <div class="w-100">
        <h2 class="mb-5">Experience</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Research Intern at Wangxuan Institute of Computer Technology</h3>
			<h4>Supervised by Prof. Jiaying Liu</h4>
            <!--<div class="subheading mb-3">Wangxuan Institute of Computer Technology, Peking University</div> !-->
            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">A Novel Benchmark for Low-light Enhancement</h3>
                <!-- <div class="subheading mb-3">Intelitec Solutions</div> -->
                  <!--
                <p>This is a project for designing and collecting data for pelvis radiograph. To assist the diagnosis of pelvis-related illness, we are collecting a pelvis landmark dataset collaborating with a major public hospital. I am the team leader of the dataset collection and have organized the landmark design and the annotation process. Temporarily, we have discussed the landmarks with the doctors and designed the 23 critical points for a single pelvis radiograph. I have also tried an implementation of a face landmark detection work, providing the baseline for our pelvis landmark detection.</p>
                !-->
                  <p>We present a comprehensive study and evaluation of existing single image low-light enhancement algorithms from the perspective of both human perception and machine vision. Beyond the traditional evaluations in the view of low-level vision, we make the first attempt to set and address a novel task, i.e. face detection in the low-light condition, to explore the potential of benefiting high-level vision tasks with image enhancement methods, both off-line and in an end-to-end manner.</p>
              </div>
            </div>
            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">Integrating Semantic Segmentation and Retinex Model for Low-Light Image Enhancement.</h3>
                <p>Based on the observation that various objects and backgrounds have different material, reflection and perspective attributes, regions of a single low-light image may require different adjustment and enhancement regarding contrast, illumination and noise. We propose an enhancement pipeline with three parts which effectively utilize the semantic layer information. Specifically, we extract the segmentation layer as well as the reflectance, and illumination, and concurrently enhance every separate region, i.g. sky, ground and objects for outdoor scenes.</p>
              </div>
            </div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2017 - June 2020</span>
          </div>
		  
        </div>
		
		<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Remote Research Intern at King Abdullah University of Science and Technology (KAUST)</h3>
			<h4>Supervised by Prof. Mohamed Elhoseiny</h4>
            <!--<div class="subheading mb-3">Wangxuan Institute of Computer Technology, Peking University</div> !-->
            <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">Multimodal Agentic Flow for Reasoning and Knowledge-based VQA</h3>
                <!-- <div class="subheading mb-3">Intelitec Solutions</div> -->
                  <!--
                <p>This is a project for designing and collecting data for pelvis radiograph. To assist the diagnosis of pelvis-related illness, we are collecting a pelvis landmark dataset collaborating with a major public hospital. I am the team leader of the dataset collection and have organized the landmark design and the annotation process. Temporarily, we have discussed the landmarks with the doctors and designed the 23 critical points for a single pelvis radiograph. I have also tried an implementation of a face landmark detection work, providing the baseline for our pelvis landmark detection.</p>
                !-->
                  <p>With the initial exploration to Visual Chain-of-Thought(VCoT) and prompt engineering/programming, we integrate the multimodal understanding property to a programmable prompting codebase.
						Then we conduct experiments on traditional and latest Visual Question Answering(VQA) benchmarks to spot the challenges of the increasingly complex multimodal tasks.
						With continuously updated tools such as Object Detection, Google Lens, Wikipedia Retrieval, we are now developing an agentic flow to handle reasoning and knowledge-based VQA tasks with planning and reflexion.
				  </p>
              </div>
            </div>
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">March 2024 - August 2024</span>
          </div>
		  
        </div>
		
		<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
		  <div class="resume-content">
			<h3 class="mb-0">Professional Experiences</h3>
		<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">Intern of Machine Learning Algorithms</h3>
				<h5>4Paradigm, Beijing</h5>
                <p> Applying Graph Neural Networks to Sales Volume Forecasting</p>
              </div>
            </div>
			
			<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">Intern Researcher of Computer Vision</h3>
				<h5>SenseTime, Shanghai</h5>
                <p> Portrait Matting on Mobile Devices: Towards App development with limited memory</p>
              </div>
            </div>

			  <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
              <div class="resume-content">
                <h4 class="mb-0">Software Engineer</h3>
				<h5>Chenyan Technology Co., Shanghai</h5>
                <p> Leaded the development of intelligent engineering design powered by artiffcial intelligence.</p>
              </div>
            </div>
		  </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2020 - June 2023</span>
          </div>		
		</div>
	      

      </div>

    </section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="education">
      <div class="w-100">
        <h2 class="mb-5">Education</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Peking University</h3>
            <div class="subheading mb-3">Bachelor of Science</div>
            <div>Department of Machine Intelligence</div>
            
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">September 2016 - June 2020</span>
          </div>
        </div>
		
		<div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <h3 class="mb-0">Nanyang Technological University</h3>
            <div class="subheading mb-3">PhD Student</div>
            <div>Hardware & Embedded Systems Lab (HESL)</div>
			<div>Supervisor: Prof. Weichen Liu</div>
            
          </div>
          <div class="resume-date text-md-right">
            <span class="text-primary">August 2024 - Present</span>
          </div>
        </div>

      </div>
    </section>
    
    <hr class="m-0">
    
    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="publications">
      <div class="w-100">
        <h2 class="mb-5">Publications</h2>

        <div class="resume-item d-flex flex-column flex-md-row justify-content-between mb-5">
          <div class="resume-content">
            <p><b>Minhao Fan</b>, Wenjing Wang, Wenhan Yang, & Jiaying Liu. <b>Integrating Semantic Segmentation and Retinex Model for Low-Light Image Enhancement.</b> ACM International Conference on Multimedia (ACM MM), 2020. </p>
            <p>Jiaying Liu, Dejia Xu, Wenhan Yang, <b>Minhao Fan</b>, & Haofeng Huang. <b>Benchmarking Low-Light Image Enhance-ment for Human Perception and Machine Intelligence.</b> International Journal of Computer Vision (IJCV), 2020.</p>
          </div>
        </div>

      </div>
    </section>   

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="courseprojects">
      <div class="w-100">
        <h2 class="mb-5">Course Projects</h2>
        <div class="subheading mb-3">Ataxx Bot</div>
        <p>I developed a bot using greedy algorithm for the game of Ataxx on Botzone in the course 'Introduction to Computation'.</p>
        <div class="subheading mb-3">The Strongest Projectile</div>
        <p>This project includes a simulation program of a WeChat game :  ‘The Strongest Projectile’. Also, we wrote a DQN algorithm which taught the agent to play the game. (Ref: <a href='https://github.com/RuntianZ/IRL'>https://github.com/RuntianZ/IRL</a>)</p>
        <div class="subheading mb-3">Group Based File Management System</div>
        <p>A simple file server which enables users to manage their files as well as setup groups with friends for file sharing. (Ref: <a href='https://github.com/XFW-go/PKU-Web-Project'>https://github.com/XFW-go/PKU-Web-Project</a>)</p>	  
		<div class="subheading mb-3">M3-VQA: A Novel Pipeline for Multilingual and Multimodal BioMedical VQA.</div>
        <p>M3-VQA leverages translation for multilingual inputs, retrieval augmented generation (RAG) for knowledge grounding, and in-context learning (ICL) with Chain-of-Thought prompting for accurate reasoning. (Ref: <a href='https://github.com/AmuroEita/M3-VQA/tree/main'>https://github.com/AmuroEita/M3-VQA/tree/main</a>)</p>	  
		<div class="subheading mb-3">LLM for SVG Image Generation and Edit</div>
        <p>We exploring the SVG generation and edit ability of LLMs and trying to improve the performance by in-context learning and Lora fine-tuning. (Ref: <a href='https://github.com/XFW-go/LLM4SVG_Gen_Edit'>https://github.com/XFW-go/LLM4SVG_Gen_Edit</a>)</p>	  		
	  </div>	
	</section>

    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="awards">
      <div class="w-100">
        <h2 class="mb-5">Awards &amp; Certifications</h2>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            May 4th Schorlarship, Peking University, 2017</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Third Prize in the 16th Annual ACM Competition at Peking University, 2017</li>
          <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            Third Prize in the 17th Annual ACM Competition at Peking University, 2018</li>
		  <li>
            <i class="fa-li fa fa-trophy text-warning"></i>
            A Low-Illumination Face Detection Method Based on Multi-Feature Fusion and A Low-Illumination Face Detection Network, Jiaying Liu, Dejia Xu, Wenhan Yang, Minhao Fan. (IPC publication G06K 9/00, Application number 201910813847.4, Peking University) 2019
			</li>
        </ul>
      </div>
    </section>
    
    <hr class="m-0">

    <section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="skills">
      <div class="w-100">
        <h2 class="mb-5">Skills</h2>

        <div class="subheading mb-3">Programming Languages &amp; Tools</div>
        <ul class="fa-ul mb-0">
          <li>
            <i class="fa-li fa fa-check"></i>
            Python</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            C++</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            HTML/CSS/JavaScript</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Tensorflow</li>
          <li>
            <i class="fa-li fa fa-check"></i>
            Pytorch</li>
        </ul>
      </div>
    </section>

  </div>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/resume.min.js"></script>

</body>

</html>
